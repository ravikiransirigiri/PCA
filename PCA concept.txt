1.Speaking broadly the whole idea of PCA(dimension reduction technique) is to convert LARGER-DIMENSION to human analyzable way i.e 3d,2d or 1d.
2.In a mean while ,we have gone through many complex mathematical derivation which has lots of significance on its own.Let me explain them one by one.
3.As we took example of 2-d model having features f1 on x-axis and f2 on y-axis.Since our main goal is to convert 2D to 1D ,We had column standardized the values because its' mean' lies at origin and
' variance' =1.The main idea behind column standardization is to obtain some kind of linearity so that we can analyze the data in more precise way removing outliers.
4.After performing column standardization we move to our main gain goal i.e converting 2d to 1d .Here we shifted our axis by some angle theta such that our axis can lie on the given dataset (points) forming new axes are f1dash and f2dash.
5.Since we converted 2d to 1d by just shifting the axis the next step is to find the direction of points with maximum variance.Here you may ask what is the use of finding direction of points with maximum variance .The answer is in order to analyze the data better, variance should more.Let me explain you in a broad way ,assume there are cars with differet colours lets say (green , blue , red,etc) .We can easily distinguish the cars based on its colour because we can differentiate colour which has lots of variations(variance).In the same way if have bunch of cars with same colour but with different shades.So which is best example to differentiate cars obviously cars which have different colors.
6.So that reason why we came across calculating variance/co variance(since mean is 0 both can be used interchangeably).After this our aim is to find the direction of max variance .So for that we have unit vector concept to determine the direction.
7.So this the reason for using concept of unit vector .Since we dont know where is the xi's(data points) lie in space so we took the concept of projection of xis on unit vector(u1).This projection in fact determines the distance between our data points (xi's) and unit vector(u1) .
8.Thats the reason we calculated minimum distance and not the maximum ,Because our unit vector should be close to data points(xi's).
9.Now in this video we came across something called eigen values and eigen vectors(probably learnt in ug).The reason we are calculating eigen values and e vectors is to find unit vector for every element in matrix(data points ) such that for obtaining max unit vector(u1) having large variance.From eigen values we can calculate corresponding eigen vector.Simply go throuh this link(https://math.stackexchange.com/questions/1425754/finding-eigenvectors-given-eigenvalues).
10.This is what i think the idea behind this bunch of videos.